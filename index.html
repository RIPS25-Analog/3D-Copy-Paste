<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="3D Copy-Paste: Physically Plausible Object Insertion for Monocular 3D Detection">
  <meta name="keywords" content="3D Copy-Paste">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>3D Copy-Paste: Physically Plausible Object Insertion for Monocular 3D Detection</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
<!--  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>-->
<!--  <script>-->
<!--    window.dataLayer = window.dataLayer || [];-->

<!--    function gtag() {-->
<!--      dataLayer.push(arguments);-->
<!--    }-->

<!--    gtag('js', new Date());-->

<!--    gtag('config', 'G-PYVRSFMDRL');-->
<!--  </script>-->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/stanford.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!--<nav class="navbar" role="navigation" aria-label="main navigation">-->
<!--  <div class="navbar-brand">-->
<!--    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">-->
<!--      <span aria-hidden="true"></span>-->
<!--      <span aria-hidden="true"></span>-->
<!--      <span aria-hidden="true"></span>-->
<!--    </a>-->
<!--  </div>-->
<!--  <div class="navbar-menu">-->
<!--    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">-->
<!--      <a class="navbar-item" href="https://keunhong.com">-->
<!--      <span class="icon">-->
<!--          <i class="fas fa-home"></i>-->
<!--      </span>-->
<!--      </a>-->

<!--      <div class="navbar-item has-dropdown is-hoverable">-->
<!--        <a class="navbar-link">-->
<!--          More Research-->
<!--        </a>-->
<!--        <div class="navbar-dropdown">-->
<!--          <a class="navbar-item" href="https://hypernerf.github.io">-->
<!--            HyperNeRF-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://nerfies.github.io">-->
<!--            Nerfies-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://latentfusion.github.io">-->
<!--            LatentFusion-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://photoshape.github.io">-->
<!--            PhotoShape-->
<!--          </a>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->

<!--  </div>-->
<!--</nav>-->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">3D Copy-Paste: Physically Plausible Object Insertion for Monocular 3D Detection</h1>

          <h3 class="title is-4">NeurIPS 2023</h3>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://gyhandy.github.io/">Yunhao Ge</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://kovenyu.com/">Hong-Xing "Koven" Yu</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=EAC-8m0AAAAJ&hl">Cheng Zhao</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=CP-YkUwAAAAJ&hl">Yuliang Guo</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=cL4bNBwAAAAJ">Xinyu Huang</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/site/liurenshomepage/">Liu Ren</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=xhUvqK8AAAAJ">Laurent Itti</a><sup>2</sup>
            </span>
            <span class="author-block">
              <a href="https://jiajunwu.com/">Jiajun Wu</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Stanford University,</span>
            <span class="author-block"><sup>2</sup>University of Southern California,</span>
            <span class="author-block"><sup>3</sup>Bosch Research North America, Bosch Center for Artificial Intelligence (BCAI)</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/pdf?id=d86B6Mdweq"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
<!--              <span class="link-block">-->
<!--                <a href="https://arxiv.org/abs/2011.12948"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="ai ai-arxiv"></i>-->
<!--                  </span>-->
<!--                  <span>arXiv</span>-->
<!--                </a>-->
<!--              </span>-->
              <!-- Video Link. -->
<!--              <span class="link-block">-->
<!--                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-youtube"></i>-->
<!--                  </span>-->
<!--                  <span>Video</span>-->
<!--                </a>-->
<!--              </span>-->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/gyhandy/3D-Copy-Paste"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
<!--              <span class="link-block">-->
<!--                <a href="https://github.com/google/nerfies/releases/tag/0.1"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="far fa-images"></i>-->
<!--                  </span>-->
<!--                  <span>Data</span>-->
<!--                  </a>-->
<!--                </span>-->


          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
            <img src="./static/images/3D-copy-paste.gif"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
<!--      <video id="teaser" autoplay muted loop playsinline height="100%">-->
<!--&lt;!&ndash;        <source src="./static/videos/teaser.mp4"&ndash;&gt;-->
<!--        <source src="./static/images/3D-copy-paste.gif"-->
<!--                type="video/mp4">-->
<!--      </video>-->
      <h2 class="subtitle has-text-centered">
        3D Copy-Paste automatically copies virtual objects and pastes them into a real scene.
        The resulting objects in the scene have 3D bounding boxes with plausible physical locations and appearances.
        The generated data trains a monocular 3D detection model and achieves SOTA.
      </h2>
                <img src="./static/images/Fig-1.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
    </div>
  </div>
</section>


<!--<section class="hero is-light is-small">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <div id="results-carousel" class="carousel results-carousel">-->
<!--        <div class="item item-steve">-->
<!--          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/steve.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-chair-tp">-->
<!--          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/chair-tp.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-shiba">-->
<!--          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/shiba.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-fullbody">-->
<!--          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/fullbody.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-blueshirt">-->
<!--          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/blueshirt.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-mask">-->
<!--          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/mask.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-coffee">-->
<!--          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/coffee.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-toby">-->
<!--          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/toby2.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
<!--          <p>-->
<!--            We present the first method capable of photorealistically reconstructing a non-rigidly-->
<!--            deforming scene using photos/videos captured casually from mobile phones.-->
<!--          </p>-->
          <p>
            A major challenge in monocular 3D object detection is the limited diversity and quantity of objects in real datasets.
            While augmenting real scenes with virtual objects holds promise to improve both the diversity and quantity of the objects,
            it remains elusive due to the lack of an effective 3D object insertion method in complex real captured scenes.
            In this work, we study augmenting complex real indoor scenes with virtual objects for monocular 3D object detection.
            The main challenge is to automatically identify plausible physical properties for virtual assets (e.g., locations, appearances, sizes, etc.) in cluttered real scenes.
            To address this challenge, we propose a physically plausible indoor 3D object insertion approach to automatically copy virtual objects
            and paste them into real scenes. The resulting objects in scenes have 3D bounding boxes with plausible physical locations and appearances.
            In particular, our method first identifies physically feasible locations and poses for the inserted objects to prevent collisions with the existing room layout.
            Subsequently, it estimates spatially-varying illumination for the insertion location,
            enabling the immersive blending of the virtual objects into the original scene with plausible appearances and cast shadows.
            We show that our augmentation method significantly improves existing monocular 3D object models and achieves state-of-the-art performance.
          </p>
<!--          <p>-->
<!--            We show that <span class="dnerf">Nerfies</span> can turn casually captured selfie-->
<!--            photos/videos into deformable NeRF-->
<!--            models that allow for photorealistic renderings of the subject from arbitrary-->
<!--            viewpoints, which we dub <i>"nerfies"</i>. We evaluate our method by collecting data-->
<!--            using a-->
<!--            rig with two mobile phones that take time-synchronized photos, yielding train/validation-->
<!--            images of the same pose at different viewpoints. We show that our method faithfully-->
<!--            reconstructs non-rigidly deforming scenes and reproduces unseen views with high-->
<!--            fidelity.-->
<!--          </p>-->
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
<!--    <div class="columns is-centered has-text-centered">-->
<!--      <div class="column is-four-fifths">-->
<!--        <h2 class="title is-3">Video</h2>-->
<!--        <div class="publication-video">-->
<!--          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"-->
<!--                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>

        <!-- Re-rendering. -->
        <h3 class="title is-4">Where and How to put the object.  </h3>
        <div class="content has-text-justified">
          <p>
            3D Copy-Paste first identifies physically feasible locations and poses for the inserted objects to prevent
            collisions with the existing room layout.
          </p>
        </div>
                <h3 class="title is-4">What illumination is on the object.  </h3>
        <div class="content has-text-justified">
          <p>
            3D Copy-Paste estimates spatially varying illumination for the insertion location, enabling the immersive
            blending of the virtual objects into the original scene with plausible appearances and cast shadows.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/Fig-2.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
        </div>
        <!--/ Re-rendering. -->
      </div>
    </div>
    <!--/ Method. -->
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">AI-generated data to train models</h2>

        <!-- Re-rendering. -->
        <h3 class="title is-4">Physically-plausible position, pose, size, and illumination leads to better monocular
detection performance  </h3>
        <div class="content has-text-centered">
          <img src="./static/images/Table-1.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
        </div>
        <div class="content has-text-justified">
          <p>
            3D Copy-Paste, which conducts physically plausible insertion, can help train a SOTA monocular 3D object detection model.
          </p>
        </div>

        <h3 class="title is-4">Ablation study on the influence of insertion illumination and position on monocular 3D
object detection  </h3>
         <div class="content has-text-centered">
          <img src="./static/images/Fig-3.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
        </div>
        <div class="content has-text-justified">
          <p>
            Visualization of different kinds of illumination on inserted objects.
          </p>
        </div>

                 <div class="content has-text-centered">
          <img src="./static/images/Table-2.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
        </div>
        <div class="content has-text-justified">
          <p>
            ImVoxelNet 3D monocular object detection performance on SUN RGB-D dataset with different kinds of illumination during insertion rendering.

          </p>
        </div>

                         <div class="content has-text-centered">
          <img src="./static/images/Table-3.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
        </div>
        <div class="content has-text-justified">
          <p>
            Considering the global context (semantic relationship of the inserted object to the whole scene) during the insertion is on par with the
            random category selecting setting, the following downstream detection model may not be sensitive to that.


          </p>
        </div>

        <!--/ Re-rendering. -->
      </div>
    </div>
    <!--/ Method. -->
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{ge2023d,
title={3D Copy-Paste: Physically Plausible Object Insertion for Monocular 3D Detection},
author={Yunhao Ge and Hong-Xing Yu and Cheng Zhao and Yuliang Guo and Xinyu Huang and Liu Ren and Laurent Itti and Jiajun Wu},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=d86B6Mdweq}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://openreview.net/pdf?id=d86B6Mdweq">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/gyhandy/3D-Copy-Paste" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The website template was borrowed from <a rel="Nerfies"
                                                href="https://nerfies.github.io/">Nerfies</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
